{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: mps (Mac GPU)\n",
      "PyTorch version: 2.9.0.dev20250704\n",
      "Using Mac Metal Performance Shaders for GPU acceleration\n",
      "PyTorch version: 2.9.0.dev20250704\n",
      "Using Mac Metal Performance Shaders for GPU acceleration\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')  # Mac Metal Performance Shaders\n",
    "    print(f\"Training on device: {device} (Mac GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Training on device: {device} (NVIDIA GPU)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f\"Training on device: {device} (CPU)\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "if device.type == 'mps':\n",
    "    print(\"Using Mac Metal Performance Shaders for GPU acceleration\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "if device.type == 'mps':\n",
    "    print(\"Using Mac Metal Performance Shaders for GPU acceleration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"Transformer layer for metabolic modeling\"\"\"\n",
    "    def __init__(self,vocab_size=115,dim=6,num_heads=2):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = dim\n",
    "\n",
    "        self.k = dim//num_heads\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.W_k = nn.Linear(dim,self.k,bias=False)\n",
    "        self.W_q = nn.Linear(dim,self.k,bias=False)\n",
    "        self.W_v = nn.Linear(dim,self.k,bias=False)\n",
    "\n",
    "        self.W_o = nn.Linear(self.k,dim)\n",
    "\n",
    "        #self.W_c = nn.Linear(vocab_size,vocab_size)\n",
    "\n",
    "    def scaled_dot_product_attention(self,keys,queries,values):\n",
    "        # Find the product if K and Q transpose and divide by the square root of the model dimension (d_model)\n",
    "\n",
    "        pre_softmax_attention_matrix = torch.einsum('bij,bkj->bik', keys,queries)/np.sqrt(self.d_model)\n",
    "        attention_matrix = torch.softmax(pre_softmax_attention_matrix,dim=-1)\n",
    "        attention_output = torch.einsum( 'bij,bjk->bik' , attention_matrix, values)\n",
    "\n",
    "        return attention_output, attention_matrix\n",
    "\n",
    "    def forward(self,x,c):\n",
    "        norm_x = self.layer_norm(x)\n",
    "        #modified_c = self.W_c(c.transpose(-2,-1)).transpose(-2,-1)\n",
    "        modified_c = c\n",
    "        \n",
    "        Q = self.W_k(norm_x)\n",
    "        K = self.W_q(norm_x)\n",
    "        V = self.W_v(norm_x)\n",
    "\n",
    "        attention_output, attention_matrix = self.scaled_dot_product_attention(Q,K,V)\n",
    "\n",
    "        #print(attention_matrix.size(),modified_c.size())\n",
    "\n",
    "        attended_c = torch.einsum('bij,bjk->bik',attention_matrix,modified_c)\n",
    "        \n",
    "        #print(c.size(),attended_c.size())\n",
    "\n",
    "        output_x = self.W_o(attention_output) + x\n",
    "        output_c = attended_c + c\n",
    "\n",
    "        return output_x, output_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "\n",
    "    def __init__(self,d_model,inner_dim_multiplier,dropout=0.1):\n",
    "        super(FeedForwardBlock, self).__init__()\n",
    "\n",
    "        self.d_model = d_model+1\n",
    "        self.inner_dim = inner_dim_multiplier*(d_model+1)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(self.d_model)\n",
    "\n",
    "        self.linear_layer_1 = nn.Linear(self.d_model,self.inner_dim)\n",
    "        self.linear_layer_2 = nn.Linear(self.inner_dim,self.d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,x,c):\n",
    "\n",
    "        y = torch.cat((x,c),2)\n",
    "        \n",
    "        norm_y = self.layer_norm(y)\n",
    "        \n",
    "        norm_y = self.linear_layer_1(norm_y)\n",
    "        norm_y = F.relu(norm_y)\n",
    "        norm_y = self.linear_layer_2(norm_y)\n",
    "\n",
    "        return norm_y + y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"Embedding layer + Attention Block + FeedForward Layer\"\"\"\n",
    "    def __init__(self,vocab_size=115,dim=6,num_heads=2,inner_dim_multiplier=5):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.d_model = dim\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.inp_embedding = nn.Embedding(vocab_size,dim)\n",
    "\n",
    "        self.attention_block = AttentionBlock(vocab_size,dim,num_heads)\n",
    "\n",
    "        self.feedforward_block = FeedForwardBlock(dim,inner_dim_multiplier)\n",
    "\n",
    "        self.linear_layer_1 = nn.Linear(vocab_size,vocab_size)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    \n",
    "    def forward(self,c):\n",
    "\n",
    "        batch_size, vocab_size, _ = c.size()\n",
    "\n",
    "        # y = torch.randint(0, vocab_size, (batch_size, vocab_size))\n",
    "        # for k in range(vocab_size):\n",
    "        #     y[:,k] = k\n",
    "\n",
    "        y = torch.arange(vocab_size,device=device).unsqueeze(0).expand(batch_size, -1)\n",
    "        \n",
    "        x = self.inp_embedding(y)\n",
    "        # print(x.size())\n",
    "        \n",
    "        output_x, output_c = self.attention_block(x,c)\n",
    "\n",
    "        output_y = self.feedforward_block(output_x,output_c)\n",
    "\n",
    "        return output_y[:,:,-1].unsqueeze(-1)\n",
    "\n",
    "        #return output_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerBlock(\n",
       "  (inp_embedding): Embedding(115, 6)\n",
       "  (attention_block): AttentionBlock(\n",
       "    (layer_norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "    (W_k): Linear(in_features=6, out_features=6, bias=False)\n",
       "    (W_q): Linear(in_features=6, out_features=6, bias=False)\n",
       "    (W_v): Linear(in_features=6, out_features=6, bias=False)\n",
       "    (W_o): Linear(in_features=6, out_features=6, bias=True)\n",
       "  )\n",
       "  (feedforward_block): FeedForwardBlock(\n",
       "    (layer_norm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear_layer_1): Linear(in_features=7, out_features=35, bias=True)\n",
       "    (linear_layer_2): Linear(in_features=35, out_features=7, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (linear_layer_1): Linear(in_features=115, out_features=115, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model=6\n",
    "num_heads=1\n",
    "inner_dim_multiplier=5\n",
    "vocab_size = 115\n",
    "\n",
    "trained_model_6_1_5_1 = TransformerBlock(vocab_size,d_model,num_heads,inner_dim_multiplier)\n",
    "trained_model_6_1_5_1.load_state_dict(torch.load('trained_model_6_1_5_1.pth'))\n",
    "\n",
    "trained_model_6_1_5_1.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps_test_ = torch.load('inputs_test.pt')\n",
    "outs_test_ = torch.load('outputs_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_0(j):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    pred_ops = trained_model_6_1_5_1(inps_test_[j,:,:].unsqueeze(0))\n",
    "    target_ops = outs_test_[j,:,:].unsqueeze(0)\n",
    "    inputs = inps_test_[j,:,:].unsqueeze(0)\n",
    "    plt.plot(pred_ops[0,:,0].cpu().detach().numpy(),color='red',label='Predicted Concentrations')\n",
    "    plt.plot(target_ops[0,:,0].cpu().detach().numpy(),color='green',label='Actual Concentrations')\n",
    "    plt.title(f\"Test Simulation Number {j}\")\n",
    "    plt.stem(inputs[0,:,0].cpu().detach().numpy(),label='Input Concentrations')\n",
    "    plt.ylim([-60,100])\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e5db38b36341ef89885c2cbcf8da9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4977, description='j', max=9954), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive_plot = interactive(plot_data_0, j=(0,inps_test_.size(0) - 1))\n",
    "output = interactive_plot.children[-1]\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biocomp-NN-nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
