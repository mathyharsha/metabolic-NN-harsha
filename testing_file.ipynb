{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: mps (Mac GPU)\n",
      "PyTorch version: 2.9.0.dev20250715\n",
      "Using Mac Metal Performance Shaders for GPU acceleration\n",
      "PyTorch version: 2.9.0.dev20250715\n",
      "Using Mac Metal Performance Shaders for GPU acceleration\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')  # Mac Metal Performance Shaders\n",
    "    print(f\"Training on device: {device} (Mac GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Training on device: {device} (NVIDIA GPU)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f\"Training on device: {device} (CPU)\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "if device.type == 'mps':\n",
    "    print(\"Using Mac Metal Performance Shaders for GPU acceleration\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "if device.type == 'mps':\n",
    "    print(\"Using Mac Metal Performance Shaders for GPU acceleration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"Transformer layer for metabolic modeling\"\"\"\n",
    "    def __init__(self,vocab_size=115,dim=6,num_heads=2):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "\n",
    "        assert dim%num_heads==0, \"model dimension must be divisible by number of heads\"\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = dim\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(dim)\n",
    "        self.num_heads = num_heads\n",
    "        self.k = dim//num_heads\n",
    "\n",
    "        self.W_k = nn.Linear(dim,self.k,bias=False)\n",
    "        self.W_q = nn.Linear(dim,self.k,bias=False)\n",
    "        self.W_v = nn.Linear(dim,self.k,bias=False)\n",
    "        self.W_o = nn.Linear(self.k,dim,bias=False)\n",
    "        #self.W_c = nn.Linear(vocab_size,vocab_size,bias=False)\n",
    "\n",
    "    def scaled_dot_product_attention(self,keys,queries,values):\n",
    "        # Find the product if K and Q transpose and divide by the square root of the model dimension (d_model)\n",
    "\n",
    "        pre_softmax_attention_matrix = torch.einsum('bij,bkj->bik', keys,queries)/np.sqrt(self.d_model)\n",
    "        attention_matrix = torch.softmax(pre_softmax_attention_matrix,dim=-1)\n",
    "        attention_output = torch.einsum( 'bij,bjk->bik' , attention_matrix, values)\n",
    "\n",
    "        return attention_output, attention_matrix\n",
    "\n",
    "    def forward(self,x,c):\n",
    "        norm_x = self.layer_norm(x)\n",
    "        #modified_c = self.W_c(c.transpose(-2,-1)).transpose(-2,-1)\n",
    "        modified_c = c\n",
    "\n",
    "        Q = self.W_k(norm_x)\n",
    "        K = self.W_q(norm_x)\n",
    "        V = self.W_v(norm_x)\n",
    "\n",
    "        attention_output, attention_matrix = self.scaled_dot_product_attention(Q,K,V)\n",
    "\n",
    "        #print(attention_matrix.size(),modified_c.size())\n",
    "\n",
    "        attended_c = torch.einsum('bij,bjk->bik',attention_matrix,modified_c)\n",
    "        \n",
    "        #print(c.size(),attended_c.size())\n",
    "\n",
    "        output_x = self.W_o(attention_output) + x*(1/self.num_heads)\n",
    "        output_c = (attended_c + c)*(1/self.num_heads)\n",
    "\n",
    "        return output_x, output_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "    \"\"\"Multi-Head Attention layer for metabolic modeling\"\"\"\n",
    "    def __init__(self,vocab_size=115,dim=6,num_heads=2):\n",
    "        super(MultiHeadAttentionBlock, self).__init__()\n",
    "\n",
    "        self.attention_blocks = nn.ModuleList([AttentionBlock(vocab_size,dim,num_heads) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self,x,c):\n",
    "\n",
    "        output_x = torch.zeros_like(x)\n",
    "        output_c = torch.zeros_like(c)\n",
    "\n",
    "        for attention_block in self.attention_blocks:\n",
    "            o_x, o_c = attention_block(x,c)\n",
    "            output_x += o_x\n",
    "            output_c += o_c\n",
    "\n",
    "        return output_x, output_c\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "\n",
    "    def __init__(self,d_model,inner_dim_multiplier,dropout=0.1):\n",
    "        super(FeedForwardBlock, self).__init__()\n",
    "\n",
    "        self.d_model = d_model+1\n",
    "        self.inner_dim = inner_dim_multiplier*(d_model+1)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(self.d_model)\n",
    "\n",
    "        self.linear_layer_1 = nn.Linear(self.d_model,self.inner_dim)\n",
    "        self.linear_layer_2 = nn.Linear(self.inner_dim,self.d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,x,c):\n",
    "\n",
    "        y = torch.cat((x,c),2)\n",
    "        \n",
    "        norm_y = self.layer_norm(y)\n",
    "        \n",
    "        norm_y = self.linear_layer_1(norm_y)\n",
    "        norm_y = F.relu(norm_y)\n",
    "        norm_y = self.linear_layer_2(norm_y)\n",
    "\n",
    "        return norm_y + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"Embedding layer + Attention Block + FeedForward Layer\"\"\"\n",
    "    def __init__(self,vocab_size=115,dim=6,num_heads=2,inner_dim_multiplier=5):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.d_model = dim\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.inp_embedding = nn.Embedding(vocab_size,dim)\n",
    "\n",
    "        self.attention_block = MultiHeadAttentionBlock(vocab_size,dim,num_heads)\n",
    "\n",
    "        self.feedforward_block = FeedForwardBlock(dim,inner_dim_multiplier)\n",
    "\n",
    "        self.linear_layer_1 = nn.Linear(vocab_size,vocab_size)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.32)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.32)\n",
    "    \n",
    "    \n",
    "    def forward(self,c):\n",
    "\n",
    "        batch_size, vocab_size, _ = c.size()\n",
    "\n",
    "        # y = torch.randint(0, vocab_size, (batch_size, vocab_size))\n",
    "        # for k in range(vocab_size):\n",
    "        #     y[:,k] = k\n",
    "\n",
    "        y = torch.arange(vocab_size,device=device).unsqueeze(0).expand(batch_size, -1)\n",
    "        \n",
    "        x = self.inp_embedding(y)\n",
    "        # print(x.size())\n",
    "        \n",
    "        output_x, output_c = self.attention_block(x,c)\n",
    "\n",
    "        output_y = self.feedforward_block(output_x,output_c)\n",
    "\n",
    "        return output_y[:,:,-1].unsqueeze(-1)\n",
    "\n",
    "        #return output_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersSeries(nn.Module):\n",
    "    def __init__(self,vocab_size=115,dim=6,num_heads=2,inner_dim_multiplier=5,num_transformers=2):\n",
    "        super(TransformersSeries, self).__init__()\n",
    "\n",
    "        self.d_model = dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_transformers = num_transformers\n",
    "\n",
    "        self.inp_embedding = nn.Embedding(vocab_size,dim)\n",
    "\n",
    "        self.attention_blocks = nn.ModuleList([MultiHeadAttentionBlock(vocab_size,dim,num_heads) for _ in range(num_transformers)])\n",
    "\n",
    "        self.feedforward_blocks = nn.ModuleList([FeedForwardBlock(dim,inner_dim_multiplier) for _ in range(num_transformers)])\n",
    "\n",
    "        self.linear_layer_1 = nn.Linear(vocab_size,vocab_size)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    \n",
    "    def forward(self,c):\n",
    "\n",
    "        batch_size, vocab_size, _ = c.size()\n",
    "\n",
    "        y = torch.arange(vocab_size,device=device).unsqueeze(0).expand(batch_size, -1)\n",
    "        \n",
    "        x = self.inp_embedding(y)\n",
    "\n",
    "        \n",
    "        # The series of transformer layers\n",
    "        for i in range(self.num_transformers):\n",
    "\n",
    "            output_x, output_c = self.attention_blocks[i](x,c)\n",
    "\n",
    "            output_y = self.feedforward_blocks[i](output_x,output_c)\n",
    "\n",
    "            x = output_y[:,:,:-1]\n",
    "            c = output_y[:,:,-1].unsqueeze(-1)\n",
    "\n",
    "        return output_y[:,:,-1].unsqueeze(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps_test_ = torch.load('inputs_test.pt')\n",
    "outs_test_ = torch.load('outputs_test.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = [\n",
    "        'EX_glc__D_e', 'EX_fru_e', 'EX_lac__D_e', 'EX_pyr_e', 'EX_ac_e',\n",
    "        'EX_akg_e', 'EX_succ_e', 'EX_fum_e', 'EX_mal__L_e', 'EX_etoh_e',\n",
    "        'EX_acald_e', 'EX_for_e', 'EX_gln__L_e', 'EX_glu__L_e',\n",
    "        'EX_co2_e', 'EX_h_e', 'EX_h2o_e', 'EX_nh4_e', 'EX_o2_e', 'EX_pi_e'\n",
    "    ]\n",
    "\n",
    "output_cols = [\n",
    "        'ACALD_flux',\n",
    "        'ACALDt_flux',\n",
    "        'ACKr_flux',\n",
    "        'ACONTa_flux',\n",
    "        'ACONTb_flux',\n",
    "        'ACt2r_flux',\n",
    "        'ADK1_flux',\n",
    "        'AKGDH_flux',\n",
    "        'AKGt2r_flux',\n",
    "        'ALCD2x_flux',\n",
    "        'ATPM_flux',\n",
    "        'ATPS4r_flux',\n",
    "        'Biomass_Ecoli_core_flux',\n",
    "        'CO2t_flux',\n",
    "        'CS_flux',\n",
    "        'CYTBD_flux',\n",
    "        'D_LACt2_flux',\n",
    "        'ENO_flux',\n",
    "        'ETOHt2r_flux',\n",
    "        'EX_ac_e_flux',\n",
    "        'EX_acald_e_flux',\n",
    "        'EX_akg_e_flux',\n",
    "        'EX_co2_e_flux',\n",
    "        'EX_etoh_e_flux',\n",
    "        'EX_for_e_flux',\n",
    "        'EX_fru_e_flux',\n",
    "        'EX_fum_e_flux',\n",
    "        'EX_glc__D_e_flux',\n",
    "        'EX_gln__L_e_flux',\n",
    "        'EX_glu__L_e_flux',\n",
    "        'EX_h_e_flux',\n",
    "        'EX_h2o_e_flux',\n",
    "        'EX_lac__D_e_flux',\n",
    "        'EX_mal__L_e_flux',\n",
    "        'EX_nh4_e_flux',\n",
    "        'EX_o2_e_flux',\n",
    "        'EX_pi_e_flux',\n",
    "        'EX_pyr_e_flux',\n",
    "        'EX_succ_e_flux',\n",
    "        'FBA_flux',\n",
    "        'FBP_flux',\n",
    "        'FORt2_flux',\n",
    "        'FORti_flux',\n",
    "        'FRD7_flux',\n",
    "        'FRUpts2_flux',\n",
    "        'FUM_flux',\n",
    "        'FUMt2_2_flux',\n",
    "        'G6PDH2r_flux',\n",
    "        'GAPD_flux',\n",
    "        'GLCpts_flux',\n",
    "        'GLNS_flux',\n",
    "        'GLNabc_flux',\n",
    "        'GLUDy_flux',\n",
    "        'GLUN_flux',\n",
    "        'GLUSy_flux',\n",
    "        'GLUt2r_flux',\n",
    "        'GND_flux',\n",
    "        'H2Ot_flux',\n",
    "        'ICDHyr_flux',\n",
    "        'ICL_flux',\n",
    "        'LDH_D_flux',\n",
    "        'MALS_flux',\n",
    "        'MALt2_2_flux',\n",
    "        'MDH_flux',\n",
    "        'ME1_flux',\n",
    "        'ME2_flux',\n",
    "        'NADH16_flux',\n",
    "        'NADTRHD_flux',\n",
    "        'NH4t_flux',\n",
    "        'O2t_flux',\n",
    "        'PDH_flux',\n",
    "        'PFK_flux',\n",
    "        'PFL_flux',\n",
    "        'PGI_flux',\n",
    "        'PGK_flux',\n",
    "        'PGL_flux',\n",
    "        'PGM_flux',\n",
    "        'PIt2r_flux',\n",
    "        'PPC_flux',\n",
    "        'PPCK_flux',\n",
    "        'PPS_flux',\n",
    "        'PTAr_flux',\n",
    "        'PYK_flux',\n",
    "        'PYRt2_flux',\n",
    "        'RPE_flux',\n",
    "        'RPI_flux',\n",
    "        'SUCCt2_2_flux',\n",
    "        'SUCCt3_flux',\n",
    "        'SUCDi_flux',\n",
    "        'SUCOAS_flux',\n",
    "        'TALA_flux',\n",
    "        'THD2_flux',\n",
    "        'TKT1_flux',\n",
    "        'TKT2_flux',\n",
    "        'TPI_flux'\n",
    "    ]\n",
    "\n",
    "all_data = input_cols + output_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformersSeries(\n",
       "  (inp_embedding): Embedding(115, 6)\n",
       "  (attention_blocks): ModuleList(\n",
       "    (0-1): 2 x MultiHeadAttentionBlock(\n",
       "      (attention_blocks): ModuleList(\n",
       "        (0-1): 2 x AttentionBlock(\n",
       "          (layer_norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "          (W_k): Linear(in_features=6, out_features=3, bias=False)\n",
       "          (W_q): Linear(in_features=6, out_features=3, bias=False)\n",
       "          (W_v): Linear(in_features=6, out_features=3, bias=False)\n",
       "          (W_o): Linear(in_features=3, out_features=6, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feedforward_blocks): ModuleList(\n",
       "    (0-1): 2 x FeedForwardBlock(\n",
       "      (layer_norm): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_layer_1): Linear(in_features=7, out_features=35, bias=True)\n",
       "      (linear_layer_2): Linear(in_features=35, out_features=7, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (linear_layer_1): Linear(in_features=115, out_features=115, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = TransformersSeries()  # Must recreate model structure\n",
    "trained_model.load_state_dict(torch.load('trained_model.pth'))\n",
    "trained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformersSeries(\n",
       "  (inp_embedding): Embedding(115, 12)\n",
       "  (attention_blocks): ModuleList(\n",
       "    (0-1): 2 x MultiHeadAttentionBlock(\n",
       "      (attention_blocks): ModuleList(\n",
       "        (0-2): 3 x AttentionBlock(\n",
       "          (layer_norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "          (W_k): Linear(in_features=12, out_features=4, bias=False)\n",
       "          (W_q): Linear(in_features=12, out_features=4, bias=False)\n",
       "          (W_v): Linear(in_features=12, out_features=4, bias=False)\n",
       "          (W_o): Linear(in_features=4, out_features=12, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feedforward_blocks): ModuleList(\n",
       "    (0-1): 2 x FeedForwardBlock(\n",
       "      (layer_norm): LayerNorm((13,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_layer_1): Linear(in_features=13, out_features=65, bias=True)\n",
       "      (linear_layer_2): Linear(in_features=65, out_features=13, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (linear_layer_1): Linear(in_features=115, out_features=115, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model_12_3_5_2 = TransformersSeries(115,12,3,5,2)\n",
    "trained_model_12_3_5_2.load_state_dict(torch.load('trained_model_12_3_5_2.pth'))\n",
    "\n",
    "trained_model_12_3_5_2.to(device) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [trained_model,trained_model_12_3_5_2]\n",
    "model_configs = ['dmodel=6,num_heads=2,inner_dim_multiplier=5,num_transformers=2','dmodel=12,num_heads=3,inner_dim_multiplier=5,num_transformers=2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(simulation,model):\n",
    "    plt.figure(figsize=(6*2, 4*2))\n",
    "    j = simulation\n",
    "    k = model\n",
    "    pred_ops = models[k](inps_test_[j,:,:].unsqueeze(0))\n",
    "    target_ops = outs_test_[j,:,:].unsqueeze(0)\n",
    "    inputs = inps_test_[j,:,:].unsqueeze(0)\n",
    "    plt.stem(inputs[0,:,0].cpu().detach().numpy(),'g',label='Input Concentrations')\n",
    "    plt.plot(pred_ops[0,:,0].cpu().detach().numpy(),color='red',label='Predicted Concentrations')\n",
    "    plt.plot(target_ops[0,:,0].cpu().detach().numpy(),color='black',label='Actual Concentrations')\n",
    "    plt.ylim([-50,100])\n",
    "    plt.legend()\n",
    "    plt.title(f\"Simulation {j}:{model_configs[k]}\")\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5df93ce461246fc91b54e6f652707ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=14932, description='simulation', max=29864), IntSlider(value=0, descript…"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive_plot = interactive(plot_data, simulation=(0, inps_test_.shape[0] - 1),model=(0,1))\n",
    "output = interactive_plot.children[-1]\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "%{text}<extra></extra>",
         "marker": {
          "color": "green",
          "size": 12
         },
         "mode": "markers",
         "name": "Input Concentrations",
         "text": [
          "EX_glc__D_e",
          "EX_fru_e",
          "EX_lac__D_e",
          "EX_pyr_e",
          "EX_ac_e",
          "EX_akg_e",
          "EX_succ_e",
          "EX_fum_e",
          "EX_mal__L_e",
          "EX_etoh_e",
          "EX_acald_e",
          "EX_for_e",
          "EX_gln__L_e",
          "EX_glu__L_e",
          "EX_co2_e",
          "EX_h_e",
          "EX_h2o_e",
          "EX_nh4_e",
          "EX_o2_e",
          "EX_pi_e"
         ],
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhM=",
          "dtype": "i1"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFK53QAAAAAAAACBBSOH6P+xRuD0AAAAAAAAAAAAAAAAAAEhCAABIQgAASEK4HiVBZmYxQkjh6kA=",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "%{text}<extra></extra>",
         "mode": "lines+markers",
         "name": "Predicted Concentrations",
         "text": [
          "EX_glc__D_e",
          "EX_fru_e",
          "EX_lac__D_e",
          "EX_pyr_e",
          "EX_ac_e",
          "EX_akg_e",
          "EX_succ_e",
          "EX_fum_e",
          "EX_mal__L_e",
          "EX_etoh_e",
          "EX_acald_e",
          "EX_for_e",
          "EX_gln__L_e",
          "EX_glu__L_e",
          "EX_co2_e",
          "EX_h_e",
          "EX_h2o_e",
          "EX_nh4_e",
          "EX_o2_e",
          "EX_pi_e",
          "ACALD_flux",
          "ACALDt_flux",
          "ACKr_flux",
          "ACONTa_flux",
          "ACONTb_flux",
          "ACt2r_flux",
          "ADK1_flux",
          "AKGDH_flux",
          "AKGt2r_flux",
          "ALCD2x_flux",
          "ATPM_flux",
          "ATPS4r_flux",
          "Biomass_Ecoli_core_flux",
          "CO2t_flux",
          "CS_flux",
          "CYTBD_flux",
          "D_LACt2_flux",
          "ENO_flux",
          "ETOHt2r_flux",
          "EX_ac_e_flux",
          "EX_acald_e_flux",
          "EX_akg_e_flux",
          "EX_co2_e_flux",
          "EX_etoh_e_flux",
          "EX_for_e_flux",
          "EX_fru_e_flux",
          "EX_fum_e_flux",
          "EX_glc__D_e_flux",
          "EX_gln__L_e_flux",
          "EX_glu__L_e_flux",
          "EX_h_e_flux",
          "EX_h2o_e_flux",
          "EX_lac__D_e_flux",
          "EX_mal__L_e_flux",
          "EX_nh4_e_flux",
          "EX_o2_e_flux",
          "EX_pi_e_flux",
          "EX_pyr_e_flux",
          "EX_succ_e_flux",
          "FBA_flux",
          "FBP_flux",
          "FORt2_flux",
          "FORti_flux",
          "FRD7_flux",
          "FRUpts2_flux",
          "FUM_flux",
          "FUMt2_2_flux",
          "G6PDH2r_flux",
          "GAPD_flux",
          "GLCpts_flux",
          "GLNS_flux",
          "GLNabc_flux",
          "GLUDy_flux",
          "GLUN_flux",
          "GLUSy_flux",
          "GLUt2r_flux",
          "GND_flux",
          "H2Ot_flux",
          "ICDHyr_flux",
          "ICL_flux",
          "LDH_D_flux",
          "MALS_flux",
          "MALt2_2_flux",
          "MDH_flux",
          "ME1_flux",
          "ME2_flux",
          "NADH16_flux",
          "NADTRHD_flux",
          "NH4t_flux",
          "O2t_flux",
          "PDH_flux",
          "PFK_flux",
          "PFL_flux",
          "PGI_flux",
          "PGK_flux",
          "PGL_flux",
          "PGM_flux",
          "PIt2r_flux",
          "PPC_flux",
          "PPCK_flux",
          "PPS_flux",
          "PTAr_flux",
          "PYK_flux",
          "PYRt2_flux",
          "RPE_flux",
          "RPI_flux",
          "SUCCt2_2_flux",
          "SUCCt3_flux",
          "SUCDi_flux",
          "SUCOAS_flux",
          "TALA_flux",
          "THD2_flux",
          "TKT1_flux",
          "TKT2_flux",
          "TPI_flux"
         ],
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+P0BBQkNERUZHSElKS0xNTk9QUVJTVFVWV1hZWltcXV5fYGFiY2RlZmdoaWprbG1ub3Bxcg==",
          "dtype": "i1"
         },
         "y": {
          "bdata": "Oi6Lv2grJb8AWFG9oLXfPsCjuz3gQjG+kFOCP9GOKb9wpOm/HFqaP8iGWr80sRJAYLqVPkCDkT4AbMe9AGhDPUB4eD980pQ/YPSiP6hvIj+OfIFAICJjP3AsfT8bHwBBrB0AQbAqfT/YSxK/7lcGQTxPVr8AzXw9T5KZQJH0OkKw0pe+bt3swcAdAEGsOERCoKEOPlv9BMAAZoE95KRAQDAPJr+u+dO/RvT7QTI4ur/AiSw/AKUuvnBQ5b4AFIs+tHtYP5Be1L4WcBfAXlT6QXD2kz5guwC+8NiXPvBTrcE0xHm/bposwOBWG7+oTmW/IAJ4vsisHb+uiSw/kJzevkh94z6nOy5BoIzbPgDt775OdM2/sCRXv0jAE7+wJ8C+rlSTQGz9qL/qIeg/iMGlP3Ds77461xrCvj0QQbDiFr9gpA4+qNcWv45yDkGDhy1BEBQMv4C6Bj/+9RFCmteav+SVUcBqJ8pBuKpWQDAzHb/MiSw/XFS1v4RIP0DQ7O++ZCucQLB9yj/oIDe/YNGaQIhaEr/spEBAYO/hvAD10r3Qnkm/4raTvwbMGb/QoeG+eP0ZQbtg/sAUXD2/6MAGvyRePb+kpXG/QE5lvw==",
          "dtype": "f4"
         }
        },
        {
         "hovertemplate": "%{text}<extra></extra>",
         "mode": "lines+markers",
         "name": "Predicted Concentrations",
         "text": [
          "EX_glc__D_e",
          "EX_fru_e",
          "EX_lac__D_e",
          "EX_pyr_e",
          "EX_ac_e",
          "EX_akg_e",
          "EX_succ_e",
          "EX_fum_e",
          "EX_mal__L_e",
          "EX_etoh_e",
          "EX_acald_e",
          "EX_for_e",
          "EX_gln__L_e",
          "EX_glu__L_e",
          "EX_co2_e",
          "EX_h_e",
          "EX_h2o_e",
          "EX_nh4_e",
          "EX_o2_e",
          "EX_pi_e",
          "ACALD_flux",
          "ACALDt_flux",
          "ACKr_flux",
          "ACONTa_flux",
          "ACONTb_flux",
          "ACt2r_flux",
          "ADK1_flux",
          "AKGDH_flux",
          "AKGt2r_flux",
          "ALCD2x_flux",
          "ATPM_flux",
          "ATPS4r_flux",
          "Biomass_Ecoli_core_flux",
          "CO2t_flux",
          "CS_flux",
          "CYTBD_flux",
          "D_LACt2_flux",
          "ENO_flux",
          "ETOHt2r_flux",
          "EX_ac_e_flux",
          "EX_acald_e_flux",
          "EX_akg_e_flux",
          "EX_co2_e_flux",
          "EX_etoh_e_flux",
          "EX_for_e_flux",
          "EX_fru_e_flux",
          "EX_fum_e_flux",
          "EX_glc__D_e_flux",
          "EX_gln__L_e_flux",
          "EX_glu__L_e_flux",
          "EX_h_e_flux",
          "EX_h2o_e_flux",
          "EX_lac__D_e_flux",
          "EX_mal__L_e_flux",
          "EX_nh4_e_flux",
          "EX_o2_e_flux",
          "EX_pi_e_flux",
          "EX_pyr_e_flux",
          "EX_succ_e_flux",
          "FBA_flux",
          "FBP_flux",
          "FORt2_flux",
          "FORti_flux",
          "FRD7_flux",
          "FRUpts2_flux",
          "FUM_flux",
          "FUMt2_2_flux",
          "G6PDH2r_flux",
          "GAPD_flux",
          "GLCpts_flux",
          "GLNS_flux",
          "GLNabc_flux",
          "GLUDy_flux",
          "GLUN_flux",
          "GLUSy_flux",
          "GLUt2r_flux",
          "GND_flux",
          "H2Ot_flux",
          "ICDHyr_flux",
          "ICL_flux",
          "LDH_D_flux",
          "MALS_flux",
          "MALt2_2_flux",
          "MDH_flux",
          "ME1_flux",
          "ME2_flux",
          "NADH16_flux",
          "NADTRHD_flux",
          "NH4t_flux",
          "O2t_flux",
          "PDH_flux",
          "PFK_flux",
          "PFL_flux",
          "PGI_flux",
          "PGK_flux",
          "PGL_flux",
          "PGM_flux",
          "PIt2r_flux",
          "PPC_flux",
          "PPCK_flux",
          "PPS_flux",
          "PTAr_flux",
          "PYK_flux",
          "PYRt2_flux",
          "RPE_flux",
          "RPI_flux",
          "SUCCt2_2_flux",
          "SUCCt3_flux",
          "SUCDi_flux",
          "SUCOAS_flux",
          "TALA_flux",
          "THD2_flux",
          "TKT1_flux",
          "TKT2_flux",
          "TPI_flux"
         ],
         "type": "scatter",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+P0BBQkNERUZHSElKS0xNTk9QUVJTVFVWV1hZWltcXV5fYGFiY2RlZmdoaWprbG1ub3Bxcg==",
          "dtype": "i1"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAzMwNA7FG4PYp3aqiUfuNAlH7jQAAAAAAAAAAAV/PNQA6dzyZI4fo/cT0GQRYLMEI/vx8/dRkEwpR+40DO/DJCAAAAAMjoJcBI4fo/AAAAAOxRuL0AAAAAdRkEQkjh+r8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgjnPBh0jNQQAAAAAAACDBZsRZwM78ssFW6hLAAAAAABSud8CA5h6/gOYePwAAAAAAAAAAAAAAAAAAAAAx5SRBAAAAAAAAAADqU9S/AAAAAKhjIz4O06ikLI5PwAAAAAAAAAAAp2f8JwAAAACHSM3BlH7jQAAAAAAAAAAAAAAAAAAAIEEeV4BBAAAAAOhtiECCwwlCAAAAAGbEWUDO/LJBYLvsQAAAAAAAAAAAGv4CvupT1D8AAAAAyOglQFbqEkAAAAAAdTD6QAAAAACKd2ooet6cQAAAAAABp+W+AaflvhSud0AAAAAAMeUkQVfzzcBHoeS9AAAAAEeh5L2wfqy+gOYevw==",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "xx = np.array([i for i in range(20)])\n",
    "\n",
    "\n",
    "# Create plotly figure\n",
    "fig_plotly = go.Figure()\n",
    "inputs = inps_test_[0,:20,:].unsqueeze(0)\n",
    "inp = inputs[0,:,0].cpu().detach().numpy()\n",
    "\n",
    "pred_ops = models[0](inps_test_[0,:,:].unsqueeze(0))\n",
    "target_ops = outs_test_[0,:,:].unsqueeze(0)\n",
    "\n",
    "fig_plotly.add_trace(go.Scatter(\n",
    "    x=xx,\n",
    "    y=inp,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=12,\n",
    "        color='green',\n",
    "    ),\n",
    "    text=[f'{all_data[i]}' \n",
    "            for i in xx],\n",
    "    hovertemplate='%{text}<extra></extra>',\n",
    "    name='Input Concentrations'\n",
    "))\n",
    "\n",
    "xxx = np.array([i for i in range(115)])\n",
    "\n",
    "fig_plotly.add_trace(go.Scatter(\n",
    "    x=xxx, \n",
    "    y = pred_ops[0,:,0].cpu().detach().numpy(), \n",
    "    mode='lines+markers', \n",
    "    text = [f'{all_data[i]}' \n",
    "            for i in xxx],\n",
    "    hovertemplate='%{text}<extra></extra>',\n",
    "    name='Predicted Concentrations'\n",
    "    ))\n",
    "\n",
    "fig_plotly.add_trace(go.Scatter(\n",
    "    x=xxx, \n",
    "    y = target_ops[0,:,0].cpu().detach().numpy(), \n",
    "    mode='lines+markers', \n",
    "    text = [f'{all_data[i]}' \n",
    "            for i in xxx],\n",
    "    hovertemplate='%{text}<extra></extra>',\n",
    "    name='Predicted Concentrations'\n",
    "    ))\n",
    "\n",
    "fig_plotly.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "        11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,\n",
       "        22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,\n",
       "        33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,\n",
       "        44.,  45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,\n",
       "        55.,  56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,\n",
       "        66.,  67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,\n",
       "        77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,\n",
       "        88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,\n",
       "        99., 100., 101., 102., 103., 104., 105., 106., 107., 108., 109.,\n",
       "       110., 111., 112., 113., 114.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx = np.linspace(0,114,115)\n",
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29865, 115, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_outs_ = models[0](inps_test_)\n",
    "pred_outs_.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29865, 115, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs_test_.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_actual(metabolite,simulation,model):  \n",
    "    pred_outs_ = models[model](inps_test_)\n",
    "    plt.scatter(pred_outs_[:,metabolite,:].cpu().detach().numpy(),outs_test_[:,metabolite,:].cpu().detach().numpy(),color='r',alpha=0.1)\n",
    "    plt.scatter(pred_outs_[simulation,metabolite,:].cpu().detach().numpy(),outs_test_[simulation,metabolite,:].cpu().detach().numpy(),color='k',alpha=0.9)\n",
    "    plt.xlim([-50,100])\n",
    "    plt.ylim([-50,100])\n",
    "    plt.grid()\n",
    "    plt.xlabel('Predicted Output')\n",
    "    plt.ylabel('Actual Output')\n",
    "    plt.title('Input Output Characterstics')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324b9efa568c481fb843c28b7d55e324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=57, description='metabolite', max=114), IntSlider(value=14932, descripti…"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive_plot = interactive(plot_pred_actual, metabolite=(0, inps_test_.shape[1] - 1), simulation = (0, inps_test_.shape[0] - 1), model = (0,1))\n",
    "output = interactive_plot.children[-1]\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio-nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
